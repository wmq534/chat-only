<!-- client/src/views/Chat.vue -->
<template>
  <div class="chat-page">
    <!-- é¡¶éƒ¨æ  -->
    <header class="chat-header">
      <div class="partner-info">
        <span class="partner-name">{{ partnerName }}</span>
        <span v-if="isPartnerOnline" class="online-dot"></span>
        <span v-if="typingUser" class="typing">æ­£åœ¨è¾“å…¥...</span>
      </div>
      <div class="header-actions">
        <button class="icon-btn" @click="startCall('audio')" title="è¯­éŸ³é€šè¯">ğŸ“</button>
        <button class="icon-btn" @click="startCall('video')" title="è§†é¢‘é€šè¯">ğŸ“¹</button>
      </div>
    </header>

    <!-- æ¶ˆæ¯åˆ—è¡¨ -->
    <main class="chat-messages" ref="messagesContainer">
      <div
        v-for="msg in messages"
        :key="msg.id"
        class="message"
        :class="{ 'message-self': msg.senderId === currentUser.id }"
      >
        <div class="message-bubble">
          <!-- æ–‡å­—æ¶ˆæ¯ -->
          <template v-if="msg.type === 'text'">
            {{ msg.content }}
          </template>

          <!-- å›¾ç‰‡æ¶ˆæ¯ -->
          <template v-else-if="msg.type === 'image'">
            <img :src="msg.content" @click="previewImage(msg.content)" />
          </template>

          <!-- è¯­éŸ³æ¶ˆæ¯ -->
          <template v-else-if="msg.type === 'audio'">
            <div class="audio-message" @click="playAudio(msg.content)">
              <span class="audio-icon">ğŸ”Š</span>
              <span class="audio-duration">{{ msg.duration }}''</span>
            </div>
          </template>

          <!-- è§†é¢‘æ¶ˆæ¯ -->
          <template v-else-if="msg.type === 'video'">
            <video :src="msg.content" controls></video>
          </template>
        </div>
        <div class="message-time">{{ formatTime(msg.createdAt) }}</div>
      </div>
    </main>

    <!-- è¾“å…¥æ  -->
    <footer class="chat-input">
      <div class="input-actions">
        <button class="icon-btn" @click="showFilePicker">ğŸ“·</button>
        <button
          class="icon-btn"
          @mousedown="startRecording"
          @mouseup="stopRecording"
          @touchstart.prevent="startRecording"
          @touchend.prevent="stopRecording"
        >ğŸ¤</button>
      </div>
      <input
        v-model="inputText"
        type="text"
        placeholder="è¾“å…¥æ¶ˆæ¯..."
        @keyup.enter="sendTextMessage"
        @input="handleTyping"
      />
      <button class="send-btn" @click="sendTextMessage" :disabled="!inputText.trim()">
        å‘é€
      </button>
    </footer>

    <!-- å½•éŸ³æç¤º -->
    <div v-if="isRecording" class="recording-overlay">
      <div class="recording-indicator">
        <span class="recording-dot"></span>
        <span>å½•éŸ³ä¸­... {{ recordingDuration }}s</span>
      </div>
    </div>

    <!-- æ¥ç”µå¼¹çª— -->
    <div v-if="incomingCall" class="call-modal">
      <div class="call-content">
        <p class="call-type">{{ incomingCall.type === 'video' ? 'ğŸ“¹ è§†é¢‘é€šè¯' : 'ğŸ“ è¯­éŸ³é€šè¯' }}</p>
        <p class="caller-name">{{ incomingCall.from.nickname }}</p>
        <div class="call-actions">
          <button class="reject-btn" @click="rejectCall">æ‹’ç»</button>
          <button class="accept-btn" @click="acceptCall">æ¥å¬</button>
        </div>
      </div>
    </div>

    <!-- é€šè¯ä¸­ç•Œé¢ -->
    <div v-if="inCall" class="call-screen">
      <video v-if="callType === 'video'" ref="remoteVideo" class="remote-video" autoplay playsinline></video>
      <div v-else class="audio-call-display">
        <span class="call-avatar">ğŸ“</span>
        <span>{{ partnerName }}</span>
      </div>
      <video v-if="callType === 'video'" ref="localVideo" class="local-video" autoplay playsinline muted></video>
      <div class="call-info">{{ callDuration }}</div>
      <div class="call-controls">
        <button class="icon-btn" @click="toggleMute">{{ isMuted ? 'ğŸ”‡' : 'ğŸ”Š' }}</button>
        <button class="end-call-btn" @click="endCall">æŒ‚æ–­</button>
        <button v-if="callType === 'video'" class="icon-btn" @click="toggleCamera">ğŸ“·</button>
      </div>
    </div>

    <!-- å›¾ç‰‡é¢„è§ˆ -->
    <div v-if="previewImageUrl" class="image-preview" @click="previewImageUrl = null">
      <img :src="previewImageUrl" />
    </div>

    <!-- éšè—çš„æ–‡ä»¶è¾“å…¥ -->
    <input type="file" ref="imageInput" accept="image/*,video/*" @change="handleFileSelect" style="display: none" />
  </div>
</template>

<script setup>
import { ref, computed, onMounted, onUnmounted, watch, nextTick } from 'vue'
import { useRouter } from 'vue-router'
import {
  connectSocket,
  disconnectSocket,
  sendMessage,
  sendTyping,
  sendCallRequest,
  sendCallAnswer,
  sendCallEnd,
  sendSdpOffer,
  sendSdpAnswer,
  sendIceCandidate,
  messages,
  onlineUsers,
  typingUser,
  incomingCall
} from '../services/socket'

const router = useRouter()

// ç”¨æˆ·ä¿¡æ¯
const currentUser = ref(JSON.parse(sessionStorage.getItem('user') || '{}'))
const partner = ref(null)

// æ¶ˆæ¯è¾“å…¥
const inputText = ref('')
const messagesContainer = ref(null)

// å½•éŸ³
const isRecording = ref(false)
const recordingDuration = ref(0)
let mediaRecorder = null
let audioChunks = []
let recordingTimer = null

// é€šè¯
const inCall = ref(false)
const callType = ref('audio')
const callDuration = ref('00:00')
const isMuted = ref(false)
const localVideo = ref(null)
const remoteVideo = ref(null)
let peerConnection = null
let localStream = null
let callTimer = null

// å›¾ç‰‡é¢„è§ˆ
const previewImageUrl = ref(null)

// æ–‡ä»¶è¾“å…¥
const imageInput = ref(null)

// è®¡ç®—å±æ€§
const partnerName = computed(() => partner.value?.nickname || 'ç­‰å¾…å¯¹æ–¹åŠ å…¥...')
const isPartnerOnline = computed(() => {
  return partner.value && onlineUsers.some(u => u.userId === partner.value.id)
})

// è·å–ç”¨æˆ·ä¿¡æ¯
onMounted(async () => {
  const token = sessionStorage.getItem('token')
  if (!token) {
    router.push('/')
    return
  }

  try {
    const res = await fetch('/api/auth/me', {
      headers: { Authorization: `Bearer ${token}` }
    })
    const data = await res.json()

    if (!res.ok) {
      sessionStorage.clear()
      router.push('/')
      return
    }

    currentUser.value = data.user
    partner.value = data.partner

    // è¿æ¥ Socket
    connectSocket(token)
  } catch (err) {
    console.error('è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥', err)
  }
})

onUnmounted(() => {
  disconnectSocket()
  if (peerConnection) {
    peerConnection.close()
  }
  if (localStream) {
    localStream.getTracks().forEach(track => track.stop())
  }
})

// è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
watch(messages, () => {
  nextTick(() => {
    if (messagesContainer.value) {
      messagesContainer.value.scrollTop = messagesContainer.value.scrollHeight
    }
  })
}, { deep: true })

// å‘é€æ–‡å­—æ¶ˆæ¯
function sendTextMessage() {
  const text = inputText.value.trim()
  if (!text) return

  sendMessage('text', text)
  inputText.value = ''
  sendTyping(false)
}

// è¾“å…¥æç¤º
let typingTimeout = null
function handleTyping() {
  sendTyping(true)
  clearTimeout(typingTimeout)
  typingTimeout = setTimeout(() => {
    sendTyping(false)
  }, 1000)
}

// æ–‡ä»¶é€‰æ‹©ï¼ˆå›¾ç‰‡/è§†é¢‘ï¼‰
function showFilePicker() {
  imageInput.value?.click()
}

async function handleFileSelect(e) {
  const file = e.target.files[0]
  if (!file) return

  const type = file.type.startsWith('video/') ? 'video' : 'image'
  await uploadAndSend(file, type)
  e.target.value = ''
}

// ä¸Šä¼ æ–‡ä»¶
async function uploadAndSend(file, type) {
  const token = sessionStorage.getItem('token')
  const formData = new FormData()
  formData.append('file', file)

  try {
    const res = await fetch('/api/upload', {
      method: 'POST',
      headers: { Authorization: `Bearer ${token}` },
      body: formData
    })

    const data = await res.json()
    if (res.ok) {
      sendMessage(type, data.url)
    }
  } catch (err) {
    console.error('ä¸Šä¼ å¤±è´¥', err)
  }
}

// å½•éŸ³åŠŸèƒ½
async function startRecording() {
  if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
    alert('å½“å‰ç¯å¢ƒä¸æ”¯æŒå½•éŸ³åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨ HTTPS è®¿é—®')
    return
  }
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
    mediaRecorder = new MediaRecorder(stream)
    audioChunks = []

    mediaRecorder.ondataavailable = (e) => {
      audioChunks.push(e.data)
    }

    mediaRecorder.onstop = async () => {
      const audioBlob = new Blob(audioChunks, { type: 'audio/webm' })
      const file = new File([audioBlob], 'audio.webm', { type: 'audio/webm' })

      const token = sessionStorage.getItem('token')
      const formData = new FormData()
      formData.append('file', file)

      try {
        const res = await fetch('/api/upload', {
          method: 'POST',
          headers: { Authorization: `Bearer ${token}` },
          body: formData
        })

        const data = await res.json()
        if (res.ok) {
          sendMessage('audio', data.url, recordingDuration.value)
        }
      } catch (err) {
        console.error('ä¸Šä¼ è¯­éŸ³å¤±è´¥', err)
      }

      stream.getTracks().forEach(track => track.stop())
    }

    mediaRecorder.start()
    isRecording.value = true
    recordingDuration.value = 0
    recordingTimer = setInterval(() => {
      recordingDuration.value++
    }, 1000)
  } catch (err) {
    console.error('æ— æ³•è·å–éº¦å…‹é£æƒé™', err)
  }
}

function stopRecording() {
  if (mediaRecorder && isRecording.value) {
    mediaRecorder.stop()
    isRecording.value = false
    clearInterval(recordingTimer)
  }
}

// æ’­æ”¾è¯­éŸ³
function playAudio(url) {
  const audio = new Audio(url)
  audio.play()
}

// å›¾ç‰‡é¢„è§ˆ
function previewImage(url) {
  previewImageUrl.value = url
}

// æ ¼å¼åŒ–æ—¶é—´
function formatTime(dateStr) {
  const date = new Date(dateStr)
  return date.toLocaleTimeString('zh-CN', { hour: '2-digit', minute: '2-digit' })
}

// ========== WebRTC é€šè¯åŠŸèƒ½ ==========

async function startCall(type) {
  if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
    alert('å½“å‰ç¯å¢ƒä¸æ”¯æŒé€šè¯åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨ HTTPS è®¿é—®')
    return
  }
  callType.value = type
  sendCallRequest(type)
  await setupPeerConnection(true)
}

function acceptCall() {
  callType.value = incomingCall.value.type
  sendCallAnswer(true)
  setupPeerConnection(false)
}

function rejectCall() {
  sendCallAnswer(false)
}

async function setupPeerConnection(isInitiator) {
  inCall.value = true

  // è·å–æœ¬åœ°åª’ä½“æµ
  const constraints = {
    audio: true,
    video: callType.value === 'video'
  }

  try {
    localStream = await navigator.mediaDevices.getUserMedia(constraints)

    if (callType.value === 'video' && localVideo.value) {
      localVideo.value.srcObject = localStream
    }
  } catch (err) {
    console.error('è·å–åª’ä½“æµå¤±è´¥', err)
    endCall()
    return
  }

  // åˆ›å»º RTCPeerConnection
  peerConnection = new RTCPeerConnection({
    iceServers: [
      { urls: 'stun:stun.l.google.com:19302' }
    ]
  })

  // æ·»åŠ æœ¬åœ°æµ
  localStream.getTracks().forEach(track => {
    peerConnection.addTrack(track, localStream)
  })

  // å¤„ç†è¿œç¨‹æµ
  peerConnection.ontrack = (event) => {
    if (callType.value === 'video' && remoteVideo.value) {
      remoteVideo.value.srcObject = event.streams[0]
    } else {
      const audio = new Audio()
      audio.srcObject = event.streams[0]
      audio.play()
    }
  }

  // ICE candidate
  peerConnection.onicecandidate = (event) => {
    if (event.candidate) {
      sendIceCandidate(event.candidate)
    }
  }

  // å¦‚æœæ˜¯å‘èµ·æ–¹ï¼Œåˆ›å»º offer
  if (isInitiator) {
    const offer = await peerConnection.createOffer()
    await peerConnection.setLocalDescription(offer)
    sendSdpOffer(offer)
  }

  // å¯åŠ¨é€šè¯è®¡æ—¶
  let seconds = 0
  callTimer = setInterval(() => {
    seconds++
    const mins = Math.floor(seconds / 60).toString().padStart(2, '0')
    const secs = (seconds % 60).toString().padStart(2, '0')
    callDuration.value = `${mins}:${secs}`
  }, 1000)
}

function endCall() {
  sendCallEnd()
  cleanupCall()
}

function cleanupCall() {
  inCall.value = false

  if (peerConnection) {
    peerConnection.close()
    peerConnection = null
  }

  if (localStream) {
    localStream.getTracks().forEach(track => track.stop())
    localStream = null
  }

  if (callTimer) {
    clearInterval(callTimer)
    callTimer = null
  }

  callDuration.value = '00:00'
}

function toggleMute() {
  if (localStream) {
    const audioTrack = localStream.getAudioTracks()[0]
    if (audioTrack) {
      audioTrack.enabled = !audioTrack.enabled
      isMuted.value = !audioTrack.enabled
    }
  }
}

function toggleCamera() {
  if (localStream) {
    const videoTrack = localStream.getVideoTracks()[0]
    if (videoTrack) {
      videoTrack.enabled = !videoTrack.enabled
    }
  }
}

// WebRTC ä¿¡ä»¤äº‹ä»¶ç›‘å¬
onMounted(() => {
  window.addEventListener('call-answer', async (e) => {
    if (e.detail.accepted) {
      // å¯¹æ–¹æ¥å¬ï¼Œç­‰å¾… answer
    } else {
      cleanupCall()
    }
  })

  window.addEventListener('call-end', () => {
    cleanupCall()
  })

  window.addEventListener('sdp-offer', async (e) => {
    if (!peerConnection) return
    await peerConnection.setRemoteDescription(new RTCSessionDescription(e.detail.sdp))
    const answer = await peerConnection.createAnswer()
    await peerConnection.setLocalDescription(answer)
    sendSdpAnswer(answer)
  })

  window.addEventListener('sdp-answer', async (e) => {
    if (!peerConnection) return
    await peerConnection.setRemoteDescription(new RTCSessionDescription(e.detail.sdp))
  })

  window.addEventListener('ice-candidate', async (e) => {
    if (!peerConnection) return
    try {
      await peerConnection.addIceCandidate(new RTCIceCandidate(e.detail.candidate))
    } catch (err) {
      console.error('æ·»åŠ  ICE candidate å¤±è´¥', err)
    }
  })
})
</script>

<style scoped>
.chat-page {
  height: 100vh;
  display: flex;
  flex-direction: column;
  background: var(--chat-bg);
}

/* é¡¶éƒ¨æ  */
.chat-header {
  background: var(--primary-color);
  color: white;
  padding: 12px 16px;
  display: flex;
  justify-content: space-between;
  align-items: center;
}

.partner-name {
  font-size: 18px;
  font-weight: 500;
}

.online-dot {
  display: inline-block;
  width: 8px;
  height: 8px;
  background: #2ecc71;
  border-radius: 50%;
  margin-left: 8px;
}

.typing {
  font-size: 12px;
  margin-left: 8px;
  opacity: 0.8;
}

.header-actions {
  display: flex;
  gap: 8px;
}

.icon-btn {
  background: transparent;
  padding: 8px;
  font-size: 20px;
}

/* æ¶ˆæ¯åˆ—è¡¨ */
.chat-messages {
  flex: 1;
  overflow-y: auto;
  padding: 16px;
}

.message {
  margin-bottom: 16px;
  display: flex;
  flex-direction: column;
  align-items: flex-start;
}

.message-self {
  align-items: flex-end;
}

.message-bubble {
  max-width: 70%;
  padding: 10px 14px;
  border-radius: 18px;
  background: var(--bubble-other);
  word-break: break-word;
}

.message-self .message-bubble {
  background: var(--bubble-self);
}

.message-bubble img {
  max-width: 200px;
  border-radius: 8px;
  cursor: pointer;
}

.message-bubble video {
  max-width: 200px;
  border-radius: 8px;
}

.audio-message {
  display: flex;
  align-items: center;
  gap: 8px;
  cursor: pointer;
  min-width: 80px;
}

.message-time {
  font-size: 11px;
  color: var(--text-secondary);
  margin-top: 4px;
}

/* è¾“å…¥æ  */
.chat-input {
  background: white;
  padding: 8px 12px;
  display: flex;
  align-items: center;
  gap: 8px;
  border-top: 1px solid var(--border-color);
}

.input-actions {
  display: flex;
  gap: 4px;
}

.chat-input input {
  flex: 1;
  border: none;
  padding: 10px;
  background: var(--bg-color);
  border-radius: 20px;
}

.send-btn {
  padding: 8px 16px;
  border-radius: 20px;
}

/* å½•éŸ³æç¤º */
.recording-overlay {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: rgba(0, 0, 0, 0.5);
  display: flex;
  align-items: center;
  justify-content: center;
}

.recording-indicator {
  background: white;
  padding: 20px 40px;
  border-radius: 12px;
  display: flex;
  align-items: center;
  gap: 12px;
}

.recording-dot {
  width: 12px;
  height: 12px;
  background: red;
  border-radius: 50%;
  animation: pulse 1s infinite;
}

@keyframes pulse {
  0%, 100% { opacity: 1; }
  50% { opacity: 0.5; }
}

/* æ¥ç”µå¼¹çª— */
.call-modal {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: rgba(0, 0, 0, 0.7);
  display: flex;
  align-items: center;
  justify-content: center;
}

.call-content {
  background: white;
  padding: 30px;
  border-radius: 16px;
  text-align: center;
}

.call-type {
  font-size: 24px;
  margin-bottom: 8px;
}

.caller-name {
  font-size: 20px;
  margin-bottom: 24px;
}

.call-actions {
  display: flex;
  gap: 16px;
  justify-content: center;
}

.reject-btn {
  background: #e74c3c;
  padding: 12px 24px;
  border-radius: 50px;
}

.accept-btn {
  background: #2ecc71;
  padding: 12px 24px;
  border-radius: 50px;
}

/* é€šè¯ä¸­ç•Œé¢ */
.call-screen {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: #1a1a1a;
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
}

.remote-video {
  width: 100%;
  height: 100%;
  object-fit: cover;
}

.local-video {
  position: absolute;
  top: 20px;
  right: 20px;
  width: 120px;
  height: 160px;
  border-radius: 8px;
  object-fit: cover;
}

.audio-call-display {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 16px;
  color: white;
  font-size: 24px;
}

.call-avatar {
  font-size: 64px;
}

.call-info {
  position: absolute;
  top: 20px;
  left: 50%;
  transform: translateX(-50%);
  color: white;
  font-size: 18px;
}

.call-controls {
  position: absolute;
  bottom: 40px;
  display: flex;
  gap: 20px;
}

.call-controls .icon-btn {
  background: rgba(255, 255, 255, 0.2);
  width: 50px;
  height: 50px;
  border-radius: 50%;
}

.end-call-btn {
  background: #e74c3c;
  width: 60px;
  height: 60px;
  border-radius: 50%;
  font-size: 14px;
}

/* å›¾ç‰‡é¢„è§ˆ */
.image-preview {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: rgba(0, 0, 0, 0.9);
  display: flex;
  align-items: center;
  justify-content: center;
  z-index: 1000;
}

.image-preview img {
  max-width: 90%;
  max-height: 90%;
}
</style>
